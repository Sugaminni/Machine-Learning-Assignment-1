{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMIzS/26hiE8gbq7KfGQwec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sugaminni/Machine-Learning-Assignment-1/blob/main/ML_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZD4Ag9SD2AS"
      },
      "outputs": [],
      "source": [
        "# Imports required libraries\n",
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Loads Wine dataset\n",
        "wine = load_wine()\n",
        "\n",
        "# Converts to a pandas DataFrame\n",
        "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "wine_df['target'] = wine.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separates features and labels\n",
        "X = wine_df.drop(\"target\", axis=1).values\n",
        "y = wine_df[\"target\"].values\n",
        "\n",
        "# Shuffles data\n",
        "idx = np.random.permutation(len(X))\n",
        "X, y = X[idx], y[idx]\n",
        "\n",
        "# 70% training, 30% testing split\n",
        "split = int(0.7 * len(X))\n",
        "Xtr, Xte = X[:split], X[split:]\n",
        "ytr, yte = y[:split], y[split:]\n",
        "\n",
        "# Standardizes using training statistics only\n",
        "mu = Xtr.mean(axis=0)\n",
        "sd = Xtr.std(axis=0)\n",
        "sd[sd == 0] = 1\n",
        "Xtr = (Xtr - mu) / sd\n",
        "Xte = (Xte - mu) / sd"
      ],
      "metadata": {
        "id": "LdlWIOFLEhuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn1(Xtr, ytr, Xte):\n",
        "    preds = []\n",
        "    for x in Xte:\n",
        "        # Euclidean distance to all training samples\n",
        "        dists = np.linalg.norm(Xtr - x, axis=1)\n",
        "        # Label of nearest neighbor\n",
        "        preds.append(ytr[np.argmin(dists)])\n",
        "    return np.array(preds)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return (y_true == y_pred).mean()\n",
        "\n",
        "# Pure KNN classification\n",
        "yp_knn = knn1(Xtr, ytr, Xte)\n",
        "print(\"KNN accuracy:\", accuracy(yte, yp_knn))\n"
      ],
      "metadata": {
        "id": "0nbaLwLRFSYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pca(X, k):\n",
        "    # Center data\n",
        "    Xc = X - X.mean(axis=0)\n",
        "    # Covariance matrix\n",
        "    C = np.cov(Xc, rowvar=False)\n",
        "    # Eigen decomposition\n",
        "    vals, vecs = np.linalg.eigh(C)\n",
        "    # Top-k eigenvectors\n",
        "    return vecs[:, np.argsort(vals)[::-1][:k]]\n",
        "\n",
        "# Reduces to 2 dimensions\n",
        "W_pca = pca(Xtr, 2)\n",
        "Xtr_p = Xtr @ W_pca\n",
        "Xte_p = Xte @ W_pca\n",
        "\n",
        "# KNN on PCA-reduced data\n",
        "yp_pca = knn1(Xtr_p, ytr, Xte_p)\n",
        "print(\"PCA + KNN accuracy:\", accuracy(yte, yp_pca))"
      ],
      "metadata": {
        "id": "vq_dE1ORFXyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lda(X, y, k):\n",
        "    classes = np.unique(y)\n",
        "    mean_total = X.mean(axis=0)\n",
        "\n",
        "    Sw = np.zeros((X.shape[1], X.shape[1]))  # Within-class scatter\n",
        "    Sb = np.zeros_like(Sw)                   # Between-class scatter\n",
        "\n",
        "    for c in classes:\n",
        "        Xc = X[y == c]\n",
        "        mean_c = Xc.mean(axis=0)\n",
        "        Sw += (Xc - mean_c).T @ (Xc - mean_c)\n",
        "        diff = (mean_c - mean_total).reshape(-1, 1)\n",
        "        Sb += Xc.shape[0] * (diff @ diff.T)\n",
        "\n",
        "    # Solves generalized eigenvalue problem\n",
        "    vals, vecs = np.linalg.eig(np.linalg.pinv(Sw) @ Sb)\n",
        "    return vecs[:, np.argsort(vals.real)[::-1][:k]].real\n",
        "\n",
        "# Projects data using LDA\n",
        "W_lda = lda(Xtr, ytr, 2)\n",
        "Xtr_l = Xtr @ W_lda\n",
        "Xte_l = Xte @ W_lda\n",
        "\n",
        "# KNN on LDA-reduced data\n",
        "yp_lda = knn1(Xtr_l, ytr, Xte_l)\n",
        "print(\"LDA + KNN accuracy:\", accuracy(yte, yp_lda))"
      ],
      "metadata": {
        "id": "lDZD1y5lFe9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lvq(Xtr, ytr, Xte, lr=0.01, epochs=30):\n",
        "    classes = np.unique(ytr)\n",
        "\n",
        "    # Initialize one prototype per class\n",
        "    protos = np.array([Xtr[ytr == c][0] for c in classes])\n",
        "    proto_labels = classes.copy()\n",
        "\n",
        "    # Trains LVQ\n",
        "    for _ in range(epochs):\n",
        "        for x, y in zip(Xtr, ytr):\n",
        "            dists = np.linalg.norm(protos - x, axis=1)\n",
        "            i = np.argmin(dists)\n",
        "            if proto_labels[i] == y:\n",
        "                protos[i] += lr * (x - protos[i])\n",
        "            else:\n",
        "                protos[i] -= lr * (x - protos[i])\n",
        "\n",
        "    # Classifies test data\n",
        "    preds = []\n",
        "    for x in Xte:\n",
        "        dists = np.linalg.norm(protos - x, axis=1)\n",
        "        preds.append(proto_labels[np.argmin(dists)])\n",
        "    return np.array(preds)\n",
        "\n",
        "yp_lvq = lvq(Xtr, ytr, Xte)\n",
        "print(\"LVQ accuracy:\", accuracy(yte, yp_lvq))"
      ],
      "metadata": {
        "id": "tbQnJfEzFfjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KNN Classifier (k = 1) was able to achieve a high accuracy by labeling the samples based on the nearest neighbor. With PCA commbined with KNN producing similar but lower accuarcy since PCA doesn't use class labels. LDA combined with KNN showed improved classification by maximizing class separation in the reduced feature space.\n",
        "Therefore, the LVQ algorithm showed lower accuracy since each class was represented by one prototype. Finally, LDA gave the best classification results."
      ],
      "metadata": {
        "id": "T1A7J4qDHD3V"
      }
    }
  ]
}